{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKOZJpSejuwQ"
      },
      "source": [
        "# SENTIMENTAL AI\n",
        "# SnT Summer Project, BCS-IITK\n",
        "## Assignment-2\n",
        "\n",
        "Reference- https://github.com/07Agarg/Natural-Language-Processing-In-Tensorflow-Course/blob/master/Week%204/NLP_Week4_Exercise_Shakespeare_Question.ipynb "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UbboSp2kgxU2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import Regularizer\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjKVL_nyg6EX",
        "outputId": "ce9f1aed-6b90-4084-c53a-73c9a363bf37"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "# !wget --no-check-certificate \\\n",
        "#     https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "#     -O /tmp/sonnets.txt\n",
        "data = open('sonnets.txt').read()\n",
        "\n",
        "\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")  #convert to lower case and then split the data on '\\n' to create a corpus of lines\n",
        "tokenizer.fit_on_texts(corpus) #fit the tokenizer on the corpus\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GnoE7fchEp6",
        "outputId": "f408d495-67a3-4ee5-ea99-13571d7ee998"
      },
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "Cannot convert a symbolic Tensor (bidirectional_1/forward_lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5220\\1075638519.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_sequence_len\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#(# Your Embedding Layer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#(# A Bidirectional LSTM Layer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#(# A dropout layer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#(# Another LSTM Layer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    219\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m--> 926\u001b[1;33m                                                 input_list)\n\u001b[0m\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m     \u001b[1;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1115\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m               \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask, initial_state, constants)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m       y = self.forward_layer(forward_inputs,\n\u001b[1;32m--> 644\u001b[1;33m                              initial_state=forward_state, **kwargs)\n\u001b[0m\u001b[0;32m    645\u001b[0m       y_rev = self.backward_layer(backward_inputs,\n\u001b[0;32m    646\u001b[0m                                   initial_state=backward_state, **kwargs)\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m--> 926\u001b[1;33m                                                 input_list)\n\u001b[0m\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m     \u001b[1;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1115\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m               \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[1;31m# LSTM does not support constants. Ignore it during process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1108\u001b[1;33m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m       init_state = get_initial_state_fn(\n\u001b[1;32m--> 646\u001b[1;33m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001b[0m\u001b[0;32m    647\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m       init_state = _generate_zero_filled_state(batch_size, self.cell.state_size,\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2522\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2523\u001b[0m     return list(_generate_zero_filled_state_for_cell(\n\u001b[1;32m-> 2524\u001b[1;33m         self, inputs, batch_size, dtype))\n\u001b[0m\u001b[0;32m   2525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2966\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2967\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2968\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   2982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2983\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2984\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_zeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2985\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2986\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcreate_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   2979\u001b[0m     \u001b[0mflat_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munnested_state_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2980\u001b[0m     \u001b[0minit_state_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size_tensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflat_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2981\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2983\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2746\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2747\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2748\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2749\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2792\u001b[0m           \u001b[1;31m# Create a constant if it won't be very big. Otherwise create a fill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2793\u001b[0m           \u001b[1;31m# op to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2794\u001b[1;33m           \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2795\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2796\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2730\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2731\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2732\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2733\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2734\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   3050\u001b[0m     \"\"\"\n\u001b[0;32m   3051\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[1;32m-> 3052\u001b[1;33m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[0;32m   3053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\learnTF\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[1;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m         \u001b[1;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m         \" a NumPy call, which is not supported\".format(self.name))\n\u001b[0m\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (bidirectional_1/forward_lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))  #(# Your Embedding Layer)\n",
        "model.add(Bidirectional(LSTM(150, return_sequences=True)))  #(# A Bidirectional LSTM Layer)\n",
        "model.add(Dropout(0.2))  #(# A dropout layer)\n",
        "model.add(LSTM(100))  #(# Another LSTM Layer)\n",
        "model.add(Dense(total_words/2, activation='relu'))  #(# A Dense Layer including regularizers)\n",
        "model.add(Dense(total_words, activation='softmax'))  #(# A Dense Layer)\n",
        "# Pick an optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')  #(# Pick a loss function and an optimizer)\n",
        "print(model.summary()) #print model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se-rEkushRht",
        "outputId": "e9e27057-b5bc-4ea1-dd41-9d625fac6521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "484/484 [==============================] - 62s 116ms/step - loss: 6.7945 - accuracy: 0.0243\n",
            "Epoch 2/100\n",
            "484/484 [==============================] - 57s 118ms/step - loss: 6.4206 - accuracy: 0.0321\n",
            "Epoch 3/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 6.2019 - accuracy: 0.0368\n",
            "Epoch 4/100\n",
            "484/484 [==============================] - 56s 115ms/step - loss: 5.9609 - accuracy: 0.0450\n",
            "Epoch 5/100\n",
            "484/484 [==============================] - 56s 115ms/step - loss: 5.6871 - accuracy: 0.0548\n",
            "Epoch 6/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 5.4094 - accuracy: 0.0730\n",
            "Epoch 7/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 5.1386 - accuracy: 0.0837\n",
            "Epoch 8/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 4.8553 - accuracy: 0.1001\n",
            "Epoch 9/100\n",
            "484/484 [==============================] - 55s 115ms/step - loss: 4.5399 - accuracy: 0.1208\n",
            "Epoch 10/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 4.2016 - accuracy: 0.1477\n",
            "Epoch 11/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 3.8504 - accuracy: 0.1811\n",
            "Epoch 12/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 3.4862 - accuracy: 0.2403\n",
            "Epoch 13/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 3.1350 - accuracy: 0.2976\n",
            "Epoch 14/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 2.8134 - accuracy: 0.3554\n",
            "Epoch 15/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 2.5188 - accuracy: 0.4100\n",
            "Epoch 16/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 2.2691 - accuracy: 0.4614\n",
            "Epoch 17/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 2.0514 - accuracy: 0.5063\n",
            "Epoch 18/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 1.8488 - accuracy: 0.5498\n",
            "Epoch 19/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 1.6966 - accuracy: 0.5808\n",
            "Epoch 20/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 1.5331 - accuracy: 0.6206\n",
            "Epoch 21/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 1.4053 - accuracy: 0.6489\n",
            "Epoch 22/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 1.2990 - accuracy: 0.6735\n",
            "Epoch 23/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 1.2087 - accuracy: 0.6925\n",
            "Epoch 24/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 1.1254 - accuracy: 0.7122\n",
            "Epoch 25/100\n",
            "484/484 [==============================] - 57s 118ms/step - loss: 1.0412 - accuracy: 0.7354\n",
            "Epoch 26/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.9741 - accuracy: 0.7526\n",
            "Epoch 27/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.9289 - accuracy: 0.7619\n",
            "Epoch 28/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.8895 - accuracy: 0.7729\n",
            "Epoch 29/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.8490 - accuracy: 0.7811\n",
            "Epoch 30/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 0.8238 - accuracy: 0.7853\n",
            "Epoch 31/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.7810 - accuracy: 0.8008\n",
            "Epoch 32/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.7680 - accuracy: 0.8011\n",
            "Epoch 33/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.7529 - accuracy: 0.8020\n",
            "Epoch 34/100\n",
            "484/484 [==============================] - 56s 115ms/step - loss: 0.7315 - accuracy: 0.8077\n",
            "Epoch 35/100\n",
            "484/484 [==============================] - 56s 116ms/step - loss: 0.7027 - accuracy: 0.8132\n",
            "Epoch 36/100\n",
            "484/484 [==============================] - 56s 115ms/step - loss: 0.6929 - accuracy: 0.8158\n",
            "Epoch 37/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.6732 - accuracy: 0.8214\n",
            "Epoch 38/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.6595 - accuracy: 0.8225\n",
            "Epoch 39/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 0.6575 - accuracy: 0.8258\n",
            "Epoch 40/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.6570 - accuracy: 0.8213\n",
            "Epoch 41/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.6497 - accuracy: 0.8271\n",
            "Epoch 42/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.6358 - accuracy: 0.8279\n",
            "Epoch 43/100\n",
            "484/484 [==============================] - 55s 115ms/step - loss: 0.6231 - accuracy: 0.8314\n",
            "Epoch 44/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 0.6272 - accuracy: 0.8289\n",
            "Epoch 45/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.6253 - accuracy: 0.8285\n",
            "Epoch 46/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.6145 - accuracy: 0.8313\n",
            "Epoch 47/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.6086 - accuracy: 0.8312\n",
            "Epoch 48/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 0.5915 - accuracy: 0.8362\n",
            "Epoch 49/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.6045 - accuracy: 0.8326\n",
            "Epoch 50/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5865 - accuracy: 0.8372\n",
            "Epoch 51/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5882 - accuracy: 0.8371\n",
            "Epoch 52/100\n",
            "484/484 [==============================] - 56s 115ms/step - loss: 0.5921 - accuracy: 0.8347\n",
            "Epoch 53/100\n",
            "484/484 [==============================] - 57s 118ms/step - loss: 0.5886 - accuracy: 0.8343\n",
            "Epoch 54/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5755 - accuracy: 0.8379\n",
            "Epoch 55/100\n",
            "484/484 [==============================] - 56s 115ms/step - loss: 0.5709 - accuracy: 0.8366\n",
            "Epoch 56/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5722 - accuracy: 0.8373\n",
            "Epoch 57/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 0.5742 - accuracy: 0.8351\n",
            "Epoch 58/100\n",
            "484/484 [==============================] - 56s 115ms/step - loss: 0.5578 - accuracy: 0.8395\n",
            "Epoch 59/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5671 - accuracy: 0.8384\n",
            "Epoch 60/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5650 - accuracy: 0.8380\n",
            "Epoch 61/100\n",
            "484/484 [==============================] - 57s 118ms/step - loss: 0.5574 - accuracy: 0.8388\n",
            "Epoch 62/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5569 - accuracy: 0.8394\n",
            "Epoch 63/100\n",
            "484/484 [==============================] - 55s 115ms/step - loss: 0.5472 - accuracy: 0.8404\n",
            "Epoch 64/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5581 - accuracy: 0.8392\n",
            "Epoch 65/100\n",
            "484/484 [==============================] - 55s 115ms/step - loss: 0.5601 - accuracy: 0.8376\n",
            "Epoch 66/100\n",
            "484/484 [==============================] - 57s 118ms/step - loss: 0.5599 - accuracy: 0.8375\n",
            "Epoch 67/100\n",
            "484/484 [==============================] - 56s 115ms/step - loss: 0.5520 - accuracy: 0.8380\n",
            "Epoch 68/100\n",
            "484/484 [==============================] - 56s 115ms/step - loss: 0.5449 - accuracy: 0.8414\n",
            "Epoch 69/100\n",
            "484/484 [==============================] - 55s 115ms/step - loss: 0.5330 - accuracy: 0.8424\n",
            "Epoch 70/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 0.5443 - accuracy: 0.8406\n",
            "Epoch 71/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5382 - accuracy: 0.8420\n",
            "Epoch 72/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5392 - accuracy: 0.8419\n",
            "Epoch 73/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5468 - accuracy: 0.8387\n",
            "Epoch 74/100\n",
            "484/484 [==============================] - 56s 115ms/step - loss: 0.5465 - accuracy: 0.8417\n",
            "Epoch 75/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 0.5384 - accuracy: 0.8424\n",
            "Epoch 76/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5261 - accuracy: 0.8434\n",
            "Epoch 77/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5309 - accuracy: 0.8417\n",
            "Epoch 78/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5351 - accuracy: 0.8402\n",
            "Epoch 79/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 0.5418 - accuracy: 0.8381\n",
            "Epoch 80/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5299 - accuracy: 0.8432\n",
            "Epoch 81/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5241 - accuracy: 0.8439\n",
            "Epoch 82/100\n",
            "484/484 [==============================] - 55s 115ms/step - loss: 0.5153 - accuracy: 0.8474\n",
            "Epoch 83/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 0.5112 - accuracy: 0.8466\n",
            "Epoch 84/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5247 - accuracy: 0.8445\n",
            "Epoch 85/100\n",
            "484/484 [==============================] - 55s 115ms/step - loss: 0.5439 - accuracy: 0.8382\n",
            "Epoch 86/100\n",
            "484/484 [==============================] - 55s 115ms/step - loss: 0.5305 - accuracy: 0.8401\n",
            "Epoch 87/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5271 - accuracy: 0.8429\n",
            "Epoch 88/100\n",
            "484/484 [==============================] - 57s 118ms/step - loss: 0.5298 - accuracy: 0.8426\n",
            "Epoch 89/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5202 - accuracy: 0.8436\n",
            "Epoch 90/100\n",
            "484/484 [==============================] - 55s 115ms/step - loss: 0.5103 - accuracy: 0.8455\n",
            "Epoch 91/100\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 0.5226 - accuracy: 0.8428\n",
            "Epoch 92/100\n",
            "484/484 [==============================] - 57s 118ms/step - loss: 0.5220 - accuracy: 0.8421\n",
            "Epoch 93/100\n",
            "484/484 [==============================] - 55s 115ms/step - loss: 0.5206 - accuracy: 0.8436\n",
            "Epoch 94/100\n",
            "484/484 [==============================] - 55s 115ms/step - loss: 0.5130 - accuracy: 0.8454\n",
            "Epoch 95/100\n",
            "484/484 [==============================] - 55s 115ms/step - loss: 0.5156 - accuracy: 0.8448\n",
            "Epoch 96/100\n",
            "484/484 [==============================] - 57s 117ms/step - loss: 0.5138 - accuracy: 0.8421\n",
            "Epoch 97/100\n",
            "484/484 [==============================] - 56s 115ms/step - loss: 0.5111 - accuracy: 0.8441\n",
            "Epoch 98/100\n",
            "484/484 [==============================] - 56s 115ms/step - loss: 0.5199 - accuracy: 0.8436\n",
            "Epoch 99/100\n",
            "484/484 [==============================] - 56s 115ms/step - loss: 0.5253 - accuracy: 0.8418\n",
            "Epoch 100/100\n",
            "484/484 [==============================] - 57s 118ms/step - loss: 0.5058 - accuracy: 0.8461\n"
          ]
        }
      ],
      "source": [
        " history = model.fit(predictors, label, epochs=60, verbose=1) #change the number of epochs after observing the plots later on at the point where the accuracy saturates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "HMq2MUuohVAw",
        "outputId": "6853c9d3-93bf-43b8-c378-edce2ca82334"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Q2VQek4ebV",
        "outputId": "af98c726-2b79-4f8f-ed5b-4245df3ffc25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Just because you are correct, does not mean that you are right seen reap seen reap hate ' seen lips of night days ' seen stand back up in thine deeds away thee or green my mind rare rare rare rare 'no ' alone ' seen seen mind halt friend ' ' back to go told more head ' bright of worth bearing him of art of art of worth of you ' in worth of you ' more nearly bright eyes of you bearing none lips of trust of pry in you more in more in more more in more in more in more in more more in more in more\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100 #Play with this quantity to change the number of words you want to see in the output after the seed_text\n",
        "\n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predict_x = model.predict(token_list)\n",
        "  classes_x = np.argmax(predict_x, axis=1)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == classes_x:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Sentimental_AI_A2_Solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 ('learnTF')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "28ef7074259f1e269e51f285c8135d97260d8acdedf81e06521710a0b16efd4d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
